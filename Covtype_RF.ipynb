{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start  0 fold at  Tue May 29 01:41:21 2018\n",
      "[[ 8865 12261     0     0    52     0     6]\n",
      " [ 1075 24618     4     0  2631     3     0]\n",
      " [    0   131  3094    10     2   339     0]\n",
      " [    0     0    94   171     0    10     0]\n",
      " [   25   167     0     0   754     4     0]\n",
      " [    1    64   118    10     1  1543     0]\n",
      " [  102     9     0     0     0     0  1940]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.88      0.42      0.57     21184\n",
      "          2       0.66      0.87      0.75     28331\n",
      "          3       0.93      0.87      0.90      3576\n",
      "          4       0.90      0.62      0.73       275\n",
      "          5       0.22      0.79      0.34       950\n",
      "          6       0.81      0.89      0.85      1737\n",
      "          7       1.00      0.95      0.97      2051\n",
      "\n",
      "avg / total       0.77      0.71      0.70     58104\n",
      "\n",
      "end  0 fold at Tue May 29 01:41:37 2018\n",
      "start  1 fold at  Tue May 29 01:41:37 2018\n",
      "[[ 7066 14065     0     0    13     0    40]\n",
      " [ 6701 21546     0     0    83     0     0]\n",
      " [    0     5  3102    85     0   384     0]\n",
      " [    0     0    41   230     0     4     0]\n",
      " [   12   196    21     0   714     7     0]\n",
      " [   10   604    47     3     4  1069     0]\n",
      " [ 1569    44     0     0     0     0   438]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.46      0.33      0.39     21184\n",
      "          2       0.59      0.76      0.67     28330\n",
      "          3       0.97      0.87      0.91      3576\n",
      "          4       0.72      0.84      0.78       275\n",
      "          5       0.88      0.75      0.81       950\n",
      "          6       0.73      0.62      0.67      1737\n",
      "          7       0.92      0.21      0.35      2051\n",
      "\n",
      "avg / total       0.59      0.59      0.57     58103\n",
      "\n",
      "end  1 fold at Tue May 29 01:41:53 2018\n",
      "start  2 fold at  Tue May 29 01:41:53 2018\n",
      "[[13919  7150     0     0     1     0   114]\n",
      " [ 5028 23247     0     0    55     0     0]\n",
      " [    0    16  3122    82     0   356     0]\n",
      " [    0     0    40   230     0     5     0]\n",
      " [   12   630     5     0   302     1     0]\n",
      " [   22   232   702     7     0   774     0]\n",
      " [  736    19     0     0     0     0  1296]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.66      0.68     21184\n",
      "          2       0.74      0.82      0.78     28330\n",
      "          3       0.81      0.87      0.84      3576\n",
      "          4       0.72      0.84      0.77       275\n",
      "          5       0.84      0.32      0.46       950\n",
      "          6       0.68      0.45      0.54      1737\n",
      "          7       0.92      0.63      0.75      2051\n",
      "\n",
      "avg / total       0.74      0.74      0.73     58103\n",
      "\n",
      "end  2 fold at Tue May 29 01:42:09 2018\n",
      "start  3 fold at  Tue May 29 01:42:09 2018\n",
      "[[11981  8071     0     0   108    34   990]\n",
      " [ 9457 18853     0     0    20     0     0]\n",
      " [    0    16  3005   134     0   421     0]\n",
      " [    0     0    23   250     0     2     0]\n",
      " [  105   402     0     0   442     0     0]\n",
      " [    8     8   837    44     6   834     0]\n",
      " [  293    50     0     0     0     0  1708]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56     21184\n",
      "          2       0.69      0.67      0.68     28330\n",
      "          3       0.78      0.84      0.81      3576\n",
      "          4       0.58      0.91      0.71       275\n",
      "          5       0.77      0.47      0.58       949\n",
      "          6       0.65      0.48      0.55      1737\n",
      "          7       0.63      0.83      0.72      2051\n",
      "\n",
      "avg / total       0.64      0.64      0.64     58102\n",
      "\n",
      "end  3 fold at Tue May 29 01:42:25 2018\n",
      "start  4 fold at  Tue May 29 01:42:25 2018\n",
      "[[12924  7190    28     0   124     3   915]\n",
      " [17931  9417    95     0   715   141    31]\n",
      " [    0    59  3055    61     0   400     0]\n",
      " [    0     0    15   251     0     9     0]\n",
      " [   27   128     3     0   780    11     0]\n",
      " [    0     4   567    32     0  1134     0]\n",
      " [  432    22     0     0     0     0  1597]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.41      0.61      0.49     21184\n",
      "          2       0.56      0.33      0.42     28330\n",
      "          3       0.81      0.85      0.83      3575\n",
      "          4       0.73      0.91      0.81       275\n",
      "          5       0.48      0.82      0.61       949\n",
      "          6       0.67      0.65      0.66      1737\n",
      "          7       0.63      0.78      0.70      2051\n",
      "\n",
      "avg / total       0.53      0.50      0.49     58101\n",
      "\n",
      "end  4 fold at Tue May 29 01:42:40 2018\n",
      "start  5 fold at  Tue May 29 01:42:40 2018\n",
      "[[12824  7073    16     0    24     4  1243]\n",
      " [ 8465 17836   568     4   819   612    26]\n",
      " [    0   145  2987   126     0   317     0]\n",
      " [    0     0    41   206     0    28     0]\n",
      " [   96   190     1     0   660     2     0]\n",
      " [    0    38   346    15     0  1338     0]\n",
      " [  500    82     0     0     1     0  1468]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.59      0.61      0.60     21184\n",
      "          2       0.70      0.63      0.66     28330\n",
      "          3       0.75      0.84      0.79      3575\n",
      "          4       0.59      0.75      0.66       275\n",
      "          5       0.44      0.70      0.54       949\n",
      "          6       0.58      0.77      0.66      1737\n",
      "          7       0.54      0.72      0.61      2051\n",
      "\n",
      "avg / total       0.65      0.64      0.64     58101\n",
      "\n",
      "end  5 fold at Tue May 29 01:42:55 2018\n",
      "start  6 fold at  Tue May 29 01:42:55 2018\n",
      "[[15101  5570     0     0     3     0   510]\n",
      " [ 8462 15313  2296    31  1396   831     1]\n",
      " [   28   197  2860    17   103   370     0]\n",
      " [    0     0    57   211     0     7     0]\n",
      " [   58   501     0     0   389     1     0]\n",
      " [    0     2   518    26     0  1191     0]\n",
      " [  390    37     0     0     0     0  1624]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.71      0.67     21184\n",
      "          2       0.71      0.54      0.61     28330\n",
      "          3       0.50      0.80      0.61      3575\n",
      "          4       0.74      0.77      0.75       275\n",
      "          5       0.21      0.41      0.27       949\n",
      "          6       0.50      0.69      0.58      1737\n",
      "          7       0.76      0.79      0.78      2051\n",
      "\n",
      "avg / total       0.65      0.63      0.63     58101\n",
      "\n",
      "end  6 fold at Tue May 29 01:43:10 2018\n",
      "start  7 fold at  Tue May 29 01:43:10 2018\n",
      "[[13219  6439     0     0     0     0  1526]\n",
      " [11596 14365   299     0  1494   400   176]\n",
      " [   18   716  2372     0   189   279     1]\n",
      " [    0     0    33   232     0     9     0]\n",
      " [   45   355    45     0   504     0     0]\n",
      " [    9   412   300     0    28   987     0]\n",
      " [   57    35     0     0     0     0  1959]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.62      0.57     21184\n",
      "          2       0.64      0.51      0.57     28330\n",
      "          3       0.78      0.66      0.72      3575\n",
      "          4       1.00      0.85      0.92       274\n",
      "          5       0.23      0.53      0.32       949\n",
      "          6       0.59      0.57      0.58      1736\n",
      "          7       0.53      0.96      0.69      2051\n",
      "\n",
      "avg / total       0.60      0.58      0.58     58099\n",
      "\n",
      "end  7 fold at Tue May 29 01:43:26 2018\n",
      "start  8 fold at  Tue May 29 01:43:26 2018\n",
      "[[14954  5750     0     0    63     0   417]\n",
      " [15539 12518     0     0    42     4   227]\n",
      " [    3   912  2428     0     0   232     0]\n",
      " [    0     0    42   229     0     3     0]\n",
      " [   25   472    86     0   342    24     0]\n",
      " [    9   557   309     0     1   860     0]\n",
      " [   58     4     0     0     0     0  1989]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.49      0.71      0.58     21184\n",
      "          2       0.62      0.44      0.52     28330\n",
      "          3       0.85      0.68      0.75      3575\n",
      "          4       1.00      0.84      0.91       274\n",
      "          5       0.76      0.36      0.49       949\n",
      "          6       0.77      0.50      0.60      1736\n",
      "          7       0.76      0.97      0.85      2051\n",
      "\n",
      "avg / total       0.60      0.57      0.57     58099\n",
      "\n",
      "end  8 fold at Tue May 29 01:43:41 2018\n",
      "start  9 fold at  Tue May 29 01:43:41 2018\n",
      "[[17775  1957    64     0     0   167  1221]\n",
      " [ 9599 13253  3777     0   137  1439   125]\n",
      " [    0   280  3014     0     7   274     0]\n",
      " [    0     0    33   232     0     9     0]\n",
      " [   38   522    51     0   332     3     3]\n",
      " [    0    93   340     0     0  1303     0]\n",
      " [   77     1     0     0     0     0  1973]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.65      0.84      0.73     21184\n",
      "          2       0.82      0.47      0.60     28330\n",
      "          3       0.41      0.84      0.56      3575\n",
      "          4       1.00      0.85      0.92       274\n",
      "          5       0.70      0.35      0.47       949\n",
      "          6       0.41      0.75      0.53      1736\n",
      "          7       0.59      0.96      0.73      2051\n",
      "\n",
      "avg / total       0.71      0.65      0.65     58099\n",
      "\n",
      "end  9 fold at Tue May 29 01:43:57 2018\n",
      "-------Average Score---------\n",
      "accuracy:  0.6249758222174361\n",
      "precision:  0.6767585950017558\n",
      "recall:  0.6862564946342585\n",
      "fscore:  0.6571934717484635\n",
      "accTime: 155.45891404151917\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "from time import ctime\n",
    "from time import time\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#upload the dataset\n",
    "data = np.loadtxt('covtype.data.csv',delimiter=',',dtype='str')\n",
    "training_data = data[:,0:54]\n",
    "labels = data[:,54]\n",
    "\n",
    "#normalization training data\n",
    "T = training_data\n",
    "T = T.astype(float)\n",
    "max_arrayT = np.max(T,axis = 0)\n",
    "min_arrayT = np.min(T,axis = 0)\n",
    "T = (T-min_arrayT)/(max_arrayT-min_arrayT)\n",
    "\n",
    "# stats arr for calculating average score over all folds\n",
    "accuracyArr = np.zeros(10)\n",
    "precisionArr = np.zeros(10)\n",
    "recallArr = np.zeros(10)\n",
    "f1Arr = np.zeros(10)\n",
    "\n",
    "# accumulate the runtime of every fold\n",
    "operaTime = 0\n",
    "k = 0\n",
    "\n",
    "# construct the RF classifier\n",
    "clf = RandomForestClassifier(max_features='sqrt', n_estimators=20, random_state=0, n_jobs = -1)\n",
    "\n",
    "# define a stratified k-fold function to split 10 fold\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "\n",
    "for train, test in skf.split(T, labels):\n",
    "    startTime = time()\n",
    "    print('start ', k, 'fold at ', ctime(startTime))\n",
    "\n",
    "    # training the RF model\n",
    "    clf.fit(T[train], labels[train])\n",
    "\n",
    "    # predict label of each test data\n",
    "    predicted = clf.predict(T[test])\n",
    "\n",
    "    # get probability of target label\n",
    "    predicted_prob = clf.predict_proba(T[test])\n",
    "\n",
    "    # get accuracy value\n",
    "    accuracy = accuracy_score(labels[test], predicted)\n",
    "\n",
    "    # get precision,recall,fscore,support value\n",
    "    precision, recall, fscore, support = precision_recall_fscore_support(labels[test], predicted)\n",
    "\n",
    "    # draw decent confusion matrix\n",
    "    print(confusion_matrix(labels[test], predicted))\n",
    "    print(classification_report(labels[test], predicted))\n",
    "\n",
    "    # get average score based on all label types\n",
    "    accuracyArr[k] = np.average(accuracy)\n",
    "    precisionArr[k] = np.average(precision)\n",
    "    recallArr[k] = np.average(recall)\n",
    "    f1Arr[k] = np.average(fscore)\n",
    "    \n",
    "    endTime = time()\n",
    "    print('end ', k, 'fold at', ctime(endTime))\n",
    "    print('\\n')\n",
    "    interval = endTime - startTime\n",
    "    operaTime += interval\n",
    "    k += 1\n",
    "\n",
    "print('-------Average Score---------')\n",
    "print('accuracy: ', np.average(accuracyArr))\n",
    "print('precision: ', np.average(precisionArr))\n",
    "print('recall: ', np.average(recallArr))\n",
    "print('fscore: ', np.average(f1Arr))\n",
    "print('operaTime:', operaTime)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
